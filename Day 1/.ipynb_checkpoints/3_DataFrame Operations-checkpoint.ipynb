{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"If you don’t want to specify the schema, Spark can infer schema\n",
    "from a sample at a lesser cost. For example, you can use the\n",
    "samplingRatio option:\n",
    "\"\"\"\n",
    "sampleDF = spark.read.option(\"samplingRatio\", 0.001).option(\"header\", True).csv(\"/home/hhhhh/Data/sf-fire-calls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: string (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: string (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: string (nullable = true)\n",
      " |-- ALSUnit: string (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: string (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: string (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_df = spark.read.csv('/home/hhhhh/Data/sf-fire-calls.csv', header=True, schema=sampleDF.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: string (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: string (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: string (nullable = true)\n",
      " |-- ALSUnit: string (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: string (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: string (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a distributed DataFrame composed of San Francisco Fire Department calls in memory, the first thing you as a developer will want to do is examine\n",
    "your data to see what the columns look like. Are they of the correct types? Do any of\n",
    "them need to be converted to different types? Do they have null values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projections and filters:\n",
    "A <i>projection</i> in relational parlance is a way to return only the\n",
    "rows matching a certain relational condition by using filters. In Spark, projections are\n",
    "done with the <b>select()</b> method, while filters can be expressed using the <b>filter()</b> or\n",
    "<b>where()</b> method. We can use this technique to examine specific aspects of our SF Fire\n",
    "Department data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_fire_df = (fire_df\n",
    "               .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    "               .where(col(\"CallType\") != \"Medical Incident\"))\n",
    "\n",
    "few_fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_df\n",
    " .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    " .where(fire_df[\"CallType\"] != \"Medical Incident\")).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to know how many distinct <b>CallTypes</b> were recorded as the causes\n",
    "of the fire calls? These simple and expressive queries do the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_df.select('CallType').where(col('CallType').isNotNull())\n",
    " .agg(countDistinct('CallType').alias('DistinctCallTypes')).show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the distinct call types in the data set using these queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|CallType                           |\n",
      "+-----------------------------------+\n",
      "|Elevator / Escalator Rescue        |\n",
      "|Marine Fire                        |\n",
      "|Aircraft Emergency                 |\n",
      "|Confined Space / Structure Collapse|\n",
      "|Administrative                     |\n",
      "|Alarms                             |\n",
      "|Odor (Strange / Unknown)           |\n",
      "|Citizen Assist / Service Call      |\n",
      "|HazMat                             |\n",
      "|Watercraft in Distress             |\n",
      "+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.select('CallType').where(col('CallType').isNotNull()).distinct().show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming, adding, and dropping columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns with the <b>withColumnRenamed()</b>\n",
    "method. For instance, let’s change the name of our <b>Delay</b> column to <b>ResponseDelayedinMins</b> and take a look at the response times that were longer than five minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fire_df = fire_df.withColumnRenamed('Delay',\"ResponseDelayedMins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font color='red'>Note:</font></b> Because DataFrame transformations are immutable, when we\n",
    "rename a column using <b>withColumnRenamed()</b> we get a new Data‐\n",
    "Frame while retaining the original with the old column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: string (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: string (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: string (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: string (nullable = true)\n",
      " |-- ALSUnit: string (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: string (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: string (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- ResponseDelayedMins: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|ResponseDelayedMins|\n",
      "+-------------------+\n",
      "|6.25               |\n",
      "|7.25               |\n",
      "|11.916667          |\n",
      "|8.633333           |\n",
      "|95.28333           |\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(new_fire_df.select('ResponseDelayedMins').where(col('ResponseDelayedMins')>5)\n",
    ".show(5,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>--</b> Modifying the contents of a column or its type are common operations during data exploration. In some cases the data is raw or dirty, or its types are not amenable to being supplied as arguments to relational operators.<br>\n",
    "<b>--</b> For example, in our <b>SF Fire</b>\n",
    "Department data set, the columns <b>CallDate , WatchDate , and AlarmDtTm</b> are strings\n",
    "rather than either <b>Unix timestamps</b> or <b>SQL dates</b>, both of which Spark supports and\n",
    "can easily manipulate during transformations or actions (e.g., during a date- or time-\n",
    "based analysis of the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "<ol>\n",
    "    <li>Convert the existing column’s data type from string to a Spark-supported timestamp.</li>\n",
    "    <li>Use the new format specified in the format string <b>\"MM/dd/yyyy\"</b> or <b>\"MM/dd/yyyy hh:mm:ss a\"</b> where appropriate.</li>\n",
    "    <li>After converting to the new data type, drop() the old column and append the new one specified in the first argument to the <b>withColumn()</b> method.</li>\n",
    "    <li>Assign the new modified DataFrame to <b>fire_ts_df</b></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_ts_df=(new_fire_df.withColumn('IncidentDate',to_timestamp(col(\"CallDate\"),'MM/dd/yyyy')).drop('CallDate')\n",
    "            .withColumn('OnWatchDate',to_timestamp(col('WatchDate'),'MM/dd/yyyy')).drop('WatchDate')\n",
    "            .withColumn('AvailableDtTs',to_timestamp(col('AvailableDtTm'),'MM/dd/yyyy hh:mm:ss a'))\n",
    "            .drop('AvailableDtTm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTs      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_ts_df.select(['IncidentDate','OnWatchDate','AvailableDtTs']).show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have modified the dates, we can query using functions from <b>spark.sql.functions</b> like <b>month() , year() , and day()</b> to explore our data further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(year('IncidentDate'))\n",
    " .distinct()\n",
    " .orderBy(year('IncidentDate'))\n",
    " .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have explored a number of common data operations: reading and writing DataFrames; defining a schema and using it when reading in a DataFrame; saving a DataFrame as a Parquet file or table; projecting and filtering selected columns from an existing DataFrame; and modifying, renaming, and dropping columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What were the most common types of fire calls? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select('CallType')\n",
    " .where(col('CallType').isNotNull())\n",
    " .groupBy('CallType')\n",
    " .count()\n",
    " .orderBy('count',ascending=False)\n",
    " .show(10,False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |CCC   |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select('CallType')\n",
    " .where(col('CallType').isNotNull())\n",
    " .groupBy('CallType')\n",
    " .agg(count(col('CallType')).alias('CCC'))\n",
    " .orderBy('CCC',ascending=False)\n",
    " .show(10,False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What zip codes accounted for the most calls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|zipCode|count|\n",
      "+-------+-----+\n",
      "|94102  |21840|\n",
      "|94103  |20897|\n",
      "|94110  |14801|\n",
      "|94109  |14686|\n",
      "|94124  |9236 |\n",
      "|94112  |8421 |\n",
      "|94115  |7812 |\n",
      "|94107  |6941 |\n",
      "|94122  |6355 |\n",
      "|94133  |6246 |\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select('zipCode')\n",
    " .where(col('zipCode').isNotNull())\n",
    " .groupBy('zipCode')\n",
    " .count()\n",
    " .orderBy('count',ascending=False)\n",
    " .show(10,False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other common DataFrame operations.\n",
    "DataFrame API provides descriptive statistical methods like <b>min() , max() , sum() , and avg()</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute the sum of alarms, the average response time, and the minimum and maximum response times to all fire calls in our SF Fire Department data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the PySpark functions in a Pythonic way so as not to conflict with the built-in Python functions:\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------------+------------------------+------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedMins)|min(ResponseDelayedMins)|max(ResponseDelayedMins)|\n",
      "+--------------+------------------------+------------------------+------------------------+\n",
      "|      176170.0|      3.8923641541750342|             0.016666668|                    99.9|\n",
      "+--------------+------------------------+------------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(F.sum(\"NumAlarms\"),F.avg(\"ResponseDelayedMins\")\n",
    "         ,F.min(\"ResponseDelayedMins\"),F.max(\"ResponseDelayedMins\"))\n",
    " .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----------------+-----------------+\n",
      "|Alarms SUM | Avg Response Mins|Min Response Mins|Max Response Mins|\n",
      "+-----------+------------------+-----------------+-----------------+\n",
      "|   176170.0|3.8923641541750342|      0.016666668|             99.9|\n",
      "+-----------+------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    " .select(F.sum(\"NumAlarms\").alias(\"Alarms SUM \"),F.avg(\"ResponseDelayedMins\").alias(\"Avg Response Mins\")\n",
    "         ,F.min(\"ResponseDelayedMins\").alias(\"Min Response Mins\")\n",
    "         ,F.max(\"ResponseDelayedMins\").alias(\"Max Response Mins\"))\n",
    " .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more advanced statistical needs common with data science workloads, read the\n",
    "API documentation for methods like <b>stat() , describe() , correlation() ,\n",
    "covariance() , sampleBy() , approxQuantile() , frequentItems()</b> , and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
